{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZhkhIRtFigCN"
   },
   "outputs": [],
   "source": [
    "# This modeling code is based on the tutorial script here:\n",
    "# https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yx7vIzvow_Gd"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAsEBnoVxAAO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JajIyFa0Ac-_",
    "outputId": "722df7e3-5bd9-444c-dae1-44cd59974628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "1LlRmAt1Aeja",
    "outputId": "76c8155a-31a9-4df8-b809-8af77efddb0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla K80\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "id": "hvXQHVT4A2Av",
    "outputId": "a6ad02e4-e9d3-4335-eee4-6eca494ee5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 767
    },
    "colab_type": "code",
    "id": "dbcieC9nA5Hp",
    "outputId": "6aa0cfb9-0c9c-4c9d-e2ba-8259bb2fc9c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 99\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sentences_tone</th>\n",
       "      <th>document_tones</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>confident</th>\n",
       "      <th>tentative</th>\n",
       "      <th>anger</th>\n",
       "      <th>analytical</th>\n",
       "      <th>fear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RT @DrDenaGrayson: ‚ÄºÔ∏è#Florida passes 100,000 #...</td>\n",
       "      <td>en</td>\n",
       "      <td>RT : ‚ÄºÔ∏è#Florida passes 100,000 #coronavirus ca...</td>\n",
       "      <td>[{'sentence_id': 0, 'text': 'RT : ‚ÄºÔ∏è#Florida p...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @DrKatrin_Rabiei: I wish the same amount of...</td>\n",
       "      <td>en</td>\n",
       "      <td>RT : I wish the same amount of people who are ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'score': 0.781809, 'tone_id': 'sadness', 'to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>#CoronaVirusFromMinorChastisement\\n\\n\"O who cl...</td>\n",
       "      <td>en</td>\n",
       "      <td>#CoronaVirusFromMinorChastisement\\n\\n\"O who cl...</td>\n",
       "      <td>[{'sentence_id': 0, 'text': '#CoronaVirusFromM...</td>\n",
       "      <td>[{'score': 0.724923, 'tone_id': 'confident', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RT @ShawnInArizona: cc: All hospital staff in ...</td>\n",
       "      <td>en</td>\n",
       "      <td>RT : cc: All hospital staff in Florida\\n\\nYour...</td>\n",
       "      <td>[{'sentence_id': 0, 'text': 'RT : cc: All hosp...</td>\n",
       "      <td>[{'score': 0.770688, 'tone_id': 'sadness', 'to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RT @DrDenaGrayson: ‚ÄºÔ∏è#Florida passes 100,000 #...</td>\n",
       "      <td>en</td>\n",
       "      <td>RT : ‚ÄºÔ∏è#Florida passes 100,000 #coronavirus ca...</td>\n",
       "      <td>[{'sentence_id': 0, 'text': 'RT : ‚ÄºÔ∏è#Florida p...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>@KBeds If that were true, why did he make a tr...</td>\n",
       "      <td>en</td>\n",
       "      <td>If that were true, why did he make a trade de...</td>\n",
       "      <td>[{'sentence_id': 0, 'text': 'If that were true...</td>\n",
       "      <td>[{'score': 0.509573, 'tone_id': 'joy', 'tone_n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>RT @jsblokland: J.P. Morgan on the #Covid19 #r...</td>\n",
       "      <td>en</td>\n",
       "      <td>RT : J.P. Morgan on the #Covid19 #recession: d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'score': 0.62573, 'tone_id': 'sadness', 'ton...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RT @aayshacader: #TVTConnect #TVT2020\\nLive Q&amp;...</td>\n",
       "      <td>en</td>\n",
       "      <td>RT : #TVTConnect #TVT2020\\nLive Q&amp;amp;A\\nüü°shor...</td>\n",
       "      <td>[{'sentence_id': 0, 'text': 'RT : #TVTConnect ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RT @21WIRE: What a f***ing gravy train this wh...</td>\n",
       "      <td>en</td>\n",
       "      <td>RT : What a f***ing gravy train this whole #Ne...</td>\n",
       "      <td>[{'sentence_id': 0, 'text': 'RT : What a f***i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RT @BerkeleyJr: Record #Covid19 case numbers a...</td>\n",
       "      <td>en</td>\n",
       "      <td>RT : Record #Covid19 case numbers aren't a \"te...</td>\n",
       "      <td>[{'sentence_id': 0, 'text': 'RT : Record #Covi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            full_text lang  ... analytical fear\n",
       "95  RT @DrDenaGrayson: ‚ÄºÔ∏è#Florida passes 100,000 #...   en  ...        NaN  NaN\n",
       "8   RT @DrKatrin_Rabiei: I wish the same amount of...   en  ...        NaN  NaN\n",
       "36  #CoronaVirusFromMinorChastisement\\n\\n\"O who cl...   en  ...        NaN  NaN\n",
       "21  RT @ShawnInArizona: cc: All hospital staff in ...   en  ...        NaN  NaN\n",
       "13  RT @DrDenaGrayson: ‚ÄºÔ∏è#Florida passes 100,000 #...   en  ...        NaN  NaN\n",
       "97  @KBeds If that were true, why did he make a tr...   en  ...        NaN  NaN\n",
       "88  RT @jsblokland: J.P. Morgan on the #Covid19 #r...   en  ...        NaN  NaN\n",
       "42  RT @aayshacader: #TVTConnect #TVT2020\\nLive Q&...   en  ...        NaN  NaN\n",
       "24  RT @21WIRE: What a f***ing gravy train this wh...   en  ...        NaN  NaN\n",
       "19  RT @BerkeleyJr: Record #Covid19 case numbers a...   en  ...        NaN  NaN\n",
       "\n",
       "[10 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"/content/sentiment_12000.csv\")\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "colab_type": "code",
    "id": "uhkKreHjBkXK",
    "outputId": "d2290fe8-b083-4323-b579-ab4b1ad88f3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "anger = df[['clean_text','joy']]\n",
    "\n",
    "anger.joy = [np.nan_to_num(x) for x in anger['joy']]\n",
    "anger = anger.astype({\"joy\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "colab_type": "code",
    "id": "h2XPkH_DBKbp",
    "outputId": "1423c73b-b085-42c1-d062-6d5ffd37008e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           clean_text  joy\n",
      "0   RT : üì¨ I delivered this ‚úâÔ∏è from Sandra, a üó≥ ve...    0\n",
      "1   RT : 500 Delta employees test positive for cov...    1\n",
      "2   RT : #Ohio's #COVID19 data for June 22, 2020.\\...    0\n",
      "3   RT : A friend's father is Covid positive and h...    1\n",
      "4   RT : #Iran:¬†Shocking charges against jailed wo...    0\n",
      "..                                                ...  ...\n",
      "94  A look at respiratory failure in young healthy...    1\n",
      "95  RT : ‚ÄºÔ∏è#Florida passes 100,000 #coronavirus ca...    0\n",
      "96  RT : This year‚Äôs challenge is to make sure tha...    0\n",
      "97   If that were true, why did he make a trade de...    1\n",
      "98  RT : JFC... This is on you,  I currently have ...    1\n",
      "\n",
      "[99 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(anger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "mfs0yaLVCIc5",
    "outputId": "40cb5c07-7a62-44c3-974a-db2ddaacabe1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>joy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT : BREAKING: COVID19 UPDATE: 2 additional de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>meanwhile, dirty infected dishes sit back ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I am raising #money to save our #family home. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>RT :   #AndrewCuomo's response is effectively,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>B.C. MLA's are back at the Legislature with th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RT : I'm raising money for a Thailand Mission ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RT : We are setting up a #Manchester  #COVID19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RT : Uganda has been able to blunt the virus a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>RT : The advice for clinically extremely vulne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RT : Three spheres of government will be in co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_text  joy\n",
       "10  RT : BREAKING: COVID19 UPDATE: 2 additional de...    0\n",
       "89      meanwhile, dirty infected dishes sit back ...    0\n",
       "14  I am raising #money to save our #family home. ...    0\n",
       "35  RT :   #AndrewCuomo's response is effectively,...    0\n",
       "50  B.C. MLA's are back at the Legislature with th...    0\n",
       "33  RT : I'm raising money for a Thailand Mission ...    1\n",
       "31  RT : We are setting up a #Manchester  #COVID19...    1\n",
       "17  RT : Uganda has been able to blunt the virus a...    0\n",
       "91  RT : The advice for clinically extremely vulne...    0\n",
       "23  RT : Three spheres of government will be in co...    0"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anger.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jl-Rly_XMob0"
   },
   "outputs": [],
   "source": [
    "# Get the lists of sentences and their labels.\n",
    "sentences = anger.clean_text.values\n",
    "labels = anger.joy.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "05e861b7834d434296a9da40c8d5e9a6",
      "9d3f8d394c38481a9372add948145432",
      "34eee56e6bb64b0f8dc0d4611514bc58",
      "99c7ee58c5ab4ac29d47af1c77d611b0",
      "b287b164182240adb879e1eda89398ce",
      "ec714a6cc3c042c0aeb0baa4fa6d0148",
      "540dbf9a417342ab8ce29409725db68d",
      "8cc70540673543abad988e9c1ee19c05"
     ]
    },
    "colab_type": "code",
    "id": "8ErbX-5iNhcb",
    "outputId": "d8f3a09b-afce-408b-c858-5143d60cb7af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e861b7834d434296a9da40c8d5e9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti‚Ä¶"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "ry_n3qifNnXM",
    "outputId": "660b79a5-a7fb-4033-e59b-64214d80273a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  RT : üì¨ I delivered this ‚úâÔ∏è from Sandra, a üó≥ verified voter in Appleton, Wis., to  and  #WI08 #WI‚Ä¶\n",
      "Tokenized:  ['rt', ':', '[UNK]', 'i', 'delivered', 'this', '[UNK]', 'from', 'sandra', ',', 'a', '[UNK]', 'verified', 'voter', 'in', 'appleton', ',', 'wi', '##s', '.', ',', 'to', 'and', '#', 'wi', '##0', '##8', '#', 'wi', '‚Ä¶']\n",
      "Token IDs:  [19387, 1024, 100, 1045, 5359, 2023, 100, 2013, 12834, 1010, 1037, 100, 20119, 14303, 1999, 26050, 1010, 15536, 2015, 1012, 1010, 2000, 1998, 1001, 15536, 2692, 2620, 1001, 15536, 1529]\n"
     ]
    }
   ],
   "source": [
    "# Print the original sentence.\n",
    "print(' Original: ', sentences[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l6w8elb-58GJ"
   },
   "source": [
    "## Sentences to IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "jUBPDnPmNp9p",
    "outputId": "efb9caf8-a733-47a2-8ec3-b273a349e6bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  RT : üì¨ I delivered this ‚úâÔ∏è from Sandra, a üó≥ verified voter in Appleton, Wis., to  and  #WI08 #WI‚Ä¶\n",
      "Token IDs: [101, 19387, 1024, 100, 1045, 5359, 2023, 100, 2013, 12834, 1010, 1037, 100, 20119, 14303, 1999, 26050, 1010, 15536, 2015, 1012, 1010, 2000, 1998, 1001, 15536, 2692, 2620, 1001, 15536, 1529, 102]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,  # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "\n",
    "                              )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lYWEQk5nObfD"
   },
   "source": [
    "## Padding & Truncating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "u9-KLCGmN6xB",
    "outputId": "e45631da-b934-4bd0-e5ae-339e3ec1be81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  80\n"
     ]
    }
   ],
   "source": [
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "TPqkrKZkOCI_",
    "outputId": "8b9ca859-61fd-45b5-8004-2e8c53bd6828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 200 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# We'll borrow the `pad_sequences` utility function to do this.\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Set the maximum sequence length.\n",
    "MAX_LEN = 200\n",
    "\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LGJG2x8EOidw"
   },
   "source": [
    "## Attention Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PHZbsYeSOQoC"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AUMyoyvHOo9H"
   },
   "source": [
    "## Train/validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TDHA8AcxOmK4"
   },
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for\n",
    "# training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use 90% for training and 10% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                            random_state=1999, test_size=0.1)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                              random_state=1999, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pcVP5QjoPTd-"
   },
   "source": [
    "## Converting to Pytorch Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aqXY3OPbPNSm"
   },
   "outputs": [],
   "source": [
    "# Convert all inputs and labels into torch tensors, the required datatype.\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xf82JfnZPZOm"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v33eEBtpPg41"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "121e7351cd3b47f5a9901219775cad7f",
      "aa43e0dacd64462593e2384e750ef7b9",
      "42452f9d1c6b4d989fce4869519243ec",
      "5ba15ef10c054478af06cc5b1d279e81",
      "5d7aaa1bcf0b45f3a31ab21bd18b2590",
      "d1176735030c4ff38672b84de54242b0",
      "8c397b135b1e431184e585bf9765e2d5",
      "0b1436dad4b74ad795682f2d2ac5db92",
      "b0d4526cb1814da6a59972f5cc205ffa",
      "c832fe0874604d058d49e7d59468ef66",
      "ea00ff6b92934efdbc6fd315f522401e",
      "fdc4f38b54ad4bbb8ea2d6f711579397",
      "5bdad959a509429db61ce88d3b09206d",
      "b563651b435648b5bc6cdfe6cb9a235b",
      "ee22cde7fd194fdd85ca095cd4e284c2",
      "d8a23be27762490ca66ac7a7136207e7"
     ]
    },
    "colab_type": "code",
    "id": "D9TuWSa3PefG",
    "outputId": "29ccadae-95df-4893-c07b-b7692f5fbb0e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121e7351cd3b47f5a9901219775cad7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_‚Ä¶"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d4526cb1814da6a59972f5cc205ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri‚Ä¶"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2,    \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TnneE0Q4QFD_"
   },
   "source": [
    "## Set Optimizer and Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ecsQWY-XPnvR"
   },
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # args.learning_rate \n",
    "                  eps = 1e-8 # args.adam_epsilon  \n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8jM1XwrP9R4"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                       num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                       num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h7hl2qYVQKXC"
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFFrud2NQBm9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ekKg0-2FQN_w"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 793
    },
    "colab_type": "code",
    "id": "FxAt4zFNQRVG",
    "outputId": "50187534-ff9d-4150-a54c-ed43498770b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:00:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:00:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:00:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:00:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 18\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ophvlNgxSuNT"
   },
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "colab_type": "code",
    "id": "-RQMCrQEQaCF",
    "outputId": "91fd9f79-1c0f-4f5e-f772-5a1a197b43bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GY6SptSQZZ1l"
   },
   "source": [
    "# Perform on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "-KaJNZmgaOp4",
    "outputId": "0ef2b974-e979-44b9-e316-55e8a8481fb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"/content/sentiment_12000.csv\")\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "anger = df[['clean_text','joy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "colab_type": "code",
    "id": "4TD4Z4NwaSf2",
    "outputId": "34dce499-d6c8-4c94-ac1d-e1cf3a82ed33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "anger.joy = [np.nan_to_num(x) for x in anger['joy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLpA6e1zaQIl"
   },
   "outputs": [],
   "source": [
    "anger = anger.astype({\"joy\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D4raPvx7Tg_K"
   },
   "outputs": [],
   "source": [
    "# Create sentence and label lists\n",
    "sentences = anger.clean_text.values\n",
    "labels = anger.joy.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask) \n",
    "\n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 16  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Ey3Q3i1VaETC",
    "outputId": "dfd34699-27da-4839-e55c-c07a0ae9e36a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 99 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "tN37q1Hdav6H",
    "outputId": "2162b986-b1f5-4c86-e447-2784ed754ecc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 31 of 99 (31.31%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (anger.joy.sum(), len(anger.joy), (anger.joy.sum() / len(anger.joy) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "YFvIcagGaz4O",
    "outputId": "5f0260f6-3eca-49a5-fbfa-42d40e763e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "  \n",
    "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
    "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "  # in to a list of 0s and 1s.\n",
    "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  \n",
    "  # Calculate and store the coef for this batch.  \n",
    "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "  matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "-U3k6ltEa65g",
    "outputId": "b467dcda-3ff5-4e9a-a332-2f551cdd5bdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BwOqO5-hb5-L"
   },
   "source": [
    "## Output Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_faiDsexc8vF"
   },
   "outputs": [],
   "source": [
    "frames = [flat_true_labels, flat_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "for1e9pddC8d"
   },
   "outputs": [],
   "source": [
    "table = pd.DataFrame(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "-2kTQoE6dGCZ",
    "outputId": "464b356c-e4ed-46cc-b723-4040e45c0ff2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   True  Pred\n",
       "0     0     0\n",
       "1     1     0\n",
       "2     0     0\n",
       "3     1     0\n",
       "4     0     0"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = table.T\n",
    "results.columns =['True', 'Pred'] \n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_xHDbPAcQ_W"
   },
   "outputs": [],
   "source": [
    "table_to_save =anger.merge(results, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HZA_4lcQb-qd"
   },
   "outputs": [],
   "source": [
    "table_to_save.to_csv('testing_data_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IBKuOQ8_eY4F"
   },
   "source": [
    "# Label Other Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "colab_type": "code",
    "id": "2O4kaGs8e8iL",
    "outputId": "08e48933-4308-4197-f2f0-8a8039e296cc"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-ba2179fce9da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the dataset into a pandas dataframe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/data_test_0308_0323.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Report the number of sentences.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of unlabeled sentences: {:,}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /content/data_test_0308_0323.csv does not exist: '/content/data_test_0308_0323.csv'"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"/content/data_test_0308_0323.csv\")\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of unlabeled sentences: {:,}\\n'.format(df.shape[0]))\n",
    "analytical = df[['clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ADDNg_0ezb2"
   },
   "outputs": [],
   "source": [
    "# Create sentence and label lists\n",
    "sentences = analytical.clean_text.values\n",
    "# labels = sadness.sadness.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask) \n",
    "\n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "# prediction_labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 16  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pMbfMQ2Fezb6"
   },
   "outputs": [],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions  = []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  # label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  # true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpl0hjpqef1h"
   },
   "outputs": [],
   "source": [
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vEykTu38k0GJ"
   },
   "outputs": [],
   "source": [
    "table1 = pd.DataFrame(flat_predictions)\n",
    "table1.columns = ['pred_anger']\n",
    "df1 = df[['text', 'timestamp', 'clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QOdrHDAa10-3"
   },
   "outputs": [],
   "source": [
    "pred_output1 = df1.merge(table1,left_index=True, right_index=True)\n",
    "pred_output1.to_csv('data_test_0324_0408_anger_lite.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1z6Onqn-fGj"
   },
   "outputs": [],
   "source": [
    "len(pred_output1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_tweets.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05e861b7834d434296a9da40c8d5e9a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_34eee56e6bb64b0f8dc0d4611514bc58",
       "IPY_MODEL_99c7ee58c5ab4ac29d47af1c77d611b0"
      ],
      "layout": "IPY_MODEL_9d3f8d394c38481a9372add948145432"
     }
    },
    "0b1436dad4b74ad795682f2d2ac5db92": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "121e7351cd3b47f5a9901219775cad7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_42452f9d1c6b4d989fce4869519243ec",
       "IPY_MODEL_5ba15ef10c054478af06cc5b1d279e81"
      ],
      "layout": "IPY_MODEL_aa43e0dacd64462593e2384e750ef7b9"
     }
    },
    "34eee56e6bb64b0f8dc0d4611514bc58": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec714a6cc3c042c0aeb0baa4fa6d0148",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b287b164182240adb879e1eda89398ce",
      "value": 231508
     }
    },
    "42452f9d1c6b4d989fce4869519243ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1176735030c4ff38672b84de54242b0",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5d7aaa1bcf0b45f3a31ab21bd18b2590",
      "value": 433
     }
    },
    "540dbf9a417342ab8ce29409725db68d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ba15ef10c054478af06cc5b1d279e81": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b1436dad4b74ad795682f2d2ac5db92",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_8c397b135b1e431184e585bf9765e2d5",
      "value": " 433/433 [00:10&lt;00:00, 41.4B/s]"
     }
    },
    "5bdad959a509429db61ce88d3b09206d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5d7aaa1bcf0b45f3a31ab21bd18b2590": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8c397b135b1e431184e585bf9765e2d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8cc70540673543abad988e9c1ee19c05": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99c7ee58c5ab4ac29d47af1c77d611b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cc70540673543abad988e9c1ee19c05",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_540dbf9a417342ab8ce29409725db68d",
      "value": " 232k/232k [00:00&lt;00:00, 304kB/s]"
     }
    },
    "9d3f8d394c38481a9372add948145432": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa43e0dacd64462593e2384e750ef7b9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0d4526cb1814da6a59972f5cc205ffa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ea00ff6b92934efdbc6fd315f522401e",
       "IPY_MODEL_fdc4f38b54ad4bbb8ea2d6f711579397"
      ],
      "layout": "IPY_MODEL_c832fe0874604d058d49e7d59468ef66"
     }
    },
    "b287b164182240adb879e1eda89398ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b563651b435648b5bc6cdfe6cb9a235b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c832fe0874604d058d49e7d59468ef66": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1176735030c4ff38672b84de54242b0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8a23be27762490ca66ac7a7136207e7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea00ff6b92934efdbc6fd315f522401e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b563651b435648b5bc6cdfe6cb9a235b",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5bdad959a509429db61ce88d3b09206d",
      "value": 440473133
     }
    },
    "ec714a6cc3c042c0aeb0baa4fa6d0148": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee22cde7fd194fdd85ca095cd4e284c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdc4f38b54ad4bbb8ea2d6f711579397": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8a23be27762490ca66ac7a7136207e7",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ee22cde7fd194fdd85ca095cd4e284c2",
      "value": " 440M/440M [00:09&lt;00:00, 44.7MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
